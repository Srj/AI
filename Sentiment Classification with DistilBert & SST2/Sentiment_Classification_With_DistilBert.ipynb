{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "Sentiment Classification With DistilBert.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ARx_MVcmcB9",
        "colab_type": "text"
      },
      "source": [
        "<h1> Sentiment Classification Using DistilBert and Pytorch</h1>\n",
        "\n",
        "In this notebook, we will see a great overview of how to classify sentences using DistilBert pretrained by HuggingFace and a fine-tuned Neural Network to classify the sentiment.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5QPWc36VI6g",
        "trusted": true,
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "d793d888-2798-4f5f-99bd-857ddc1130ae"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.11.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.91)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: tokenizers==0.7.0 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.15.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kh8a0r0VmAY",
        "trusted": true,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import torch\n",
        "import transformers\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ErQLB9ZCWGBw",
        "trusted": true,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv('https://github.com/clairett/pytorch-sentiment-classification/raw/master/data/SST2/train.tsv',delimiter='\\t',header=None)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMlzyhpjWR6W",
        "trusted": true,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = df[:2000]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OwrxrrScWVL5",
        "trusted": true,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_class, tokenizer_class, pretrained_weights = (transformers.DistilBertModel, transformers.DistilBertTokenizer,'distilbert-base-uncased')\n",
        "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
        "model = model_class.from_pretrained(pretrained_weights)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFKHel5IXEIb",
        "trusted": true,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenized = df[0].apply(lambda x: tokenizer.encode(x,add_special_tokens=True))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JX4De5eRXTmD",
        "trusted": true,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in tokenized.values:\n",
        "    if len(i) > max_len:\n",
        "        max_len = len(i)\n",
        "\n",
        "padded = np.array([i + [0]*(max_len - len(i)) for i in tokenized.values])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFv3Hr0bXr3N",
        "trusted": true,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "attention_mask = np.where(padded != 0 , 1, 0)\n",
        "attention_mask.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tlrht88nYOHI",
        "trusted": true,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_ids = torch.tensor(padded)\n",
        "attention_mask = torch.tensor(attention_mask)\n",
        "\n",
        "with torch.no_grad():\n",
        "    last_hidden_states = model(input_ids,attention_mask=attention_mask) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sg87LqgLZqlf",
        "trusted": true,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features = last_hidden_states[0][:,0,:].numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_70hkXTmZtsX",
        "trusted": true,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels = df[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9s8Z0UybGMW",
        "trusted": true,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_features, test_features, train_labels, test_labels = train_test_split(features, labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYZIYwDUbHMo",
        "trusted": true,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "parameters = {'C' : np.linspace(0.0001,100,20)}\n",
        "grid_search = GridSearchCV(LogisticRegression(),parameters)\n",
        "grid_search.fit(train_features,train_labels)\n",
        "\n",
        "print(grid_search.best_params_)\n",
        "print(grid_search.best_score_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bZu762Nb1Mg",
        "trusted": true,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr_clf = LogisticRegression(C= 5.2)\n",
        "lr_clf.fit(train_features,train_labels)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISXdNyBbcTqg",
        "trusted": true,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr_clf.score(test_features,test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_nSSsb4caOR",
        "trusted": true,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.dummy import DummyClassifier\n",
        "clf = DummyClassifier()\n",
        "\n",
        "scores = cross_val_score(clf,train_features,train_labels)\n",
        "scores.mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldUaolScdAuz",
        "colab_type": "text"
      },
      "source": [
        "<h1> Neural Networks </h1>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "in7xaAhfdN14",
        "trusted": true,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import accuracy_score\n",
        "import torch"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "oRT1v4nd_Ao1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self,df,out,max_len=96):\n",
        "        \n",
        "        self.df = df\n",
        "        self.out = out\n",
        "        self.max_len = max_len\n",
        "        self.tokenizer = transformers.DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "        \n",
        "    def __getitem__(self,index):\n",
        "        data = {}\n",
        "        row = self.df.iloc[index]\n",
        "        ids,masks,labels = self.get_input_data(row)\n",
        "        data['ids'] = torch.tensor(ids)\n",
        "        data['masks'] = masks\n",
        "        data['labels'] = torch.tensor(self.out.iloc[index].values[0],dtype=torch.float32)\n",
        "        return data\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    \n",
        "    def get_input_data(self,row):\n",
        "        ids = self.tokenizer.encode(row[0],add_special_tokens=True)\n",
        "        pad_len = self.max_len - len(ids)\n",
        "        if pad_len > 0 :\n",
        "            ids += [0]*pad_len\n",
        "        ids = torch.tensor(ids)    \n",
        "        masks = torch.where(ids != 0 , torch.tensor(1),torch.tensor(0))\n",
        "        return ids,masks,self.out.iloc[0].values\n",
        "    \n",
        "        "
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "fqTvPzPl_Ao7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv('https://github.com/clairett/pytorch-sentiment-classification/raw/master/data/SST2/train.tsv',delimiter='\\t',header=None)\n",
        "train_set,val_set = train_test_split(df,test_size = 0.2)\n",
        "train_loader = torch.utils.data.DataLoader(Dataset(pd.DataFrame(train_set[0]),pd.DataFrame(train_set[1]),max_len=80),batch_size = 32, shuffle = True, num_workers = 2)\n",
        "val_loader = torch.utils.data.DataLoader(Dataset(pd.DataFrame(val_set[0]),pd.DataFrame(val_set[1]),max_len=80),batch_size = 32,num_workers = 2)"
      ],
      "execution_count": 188,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUiCXzbpMRoh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def binary_acc(y_pred, y_test):\n",
        "    y_pred_tag = torch.round(torch.sigmoid(y_pred))\n",
        "\n",
        "    correct_results_sum = (y_pred_tag == y_test).sum().float()\n",
        "    acc = correct_results_sum/y_test.shape[0]\n",
        "    acc = torch.round(acc * 100)\n",
        "    \n",
        "    return acc.item()"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUawDIhAdHi9",
        "trusted": true,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model,self).__init__()\n",
        "        config = transformers.DistilBertConfig.from_pretrained('distilbert-base-uncased')\n",
        "        self.distilBert = transformers.DistilBertModel.from_pretrained('distilbert-base-uncased',config=config)\n",
        "        self.fc0 = nn.Linear(768,512)\n",
        "        self.d0 = nn.Dropout(0.5)\n",
        "        self.fc1 = nn.Linear(512,256)\n",
        "        self.d1 = nn.Dropout(0.5)\n",
        "        self.fc2 = nn.Linear(256,1)\n",
        "        nn.init.normal_(self.fc0.weight,std= 0.1)\n",
        "        nn.init.normal_(self.fc0.bias ,0.)\n",
        "        nn.init.normal_(self.fc1.weight,std =0.1)\n",
        "        nn.init.normal_(self.fc1.bias, 0.)\n",
        "        nn.init.normal_(self.fc2.weight,std=0.1)\n",
        "        nn.init.normal_(self.fc2.bias , 0.)\n",
        "\n",
        "        \n",
        "    def forward(self,input_ids,attention_mask):\n",
        "        hid= self.distilBert(input_ids,attention_mask = attention_mask)\n",
        "        hid= hid[0][:,0]\n",
        "        x = self.fc0(hid)\n",
        "        x = F.relu(x)\n",
        "        x = self.d0(x)\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.d1(x)\n",
        "        return self.fc2(x)\n"
      ],
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RjFAulRefcKq",
        "trusted": true,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.BCEWithLogitsLoss(reduction='mean').to('cuda')\n",
        "model = Model().to('cuda')\n",
        "for params in model.distilBert.parameters():\n",
        "    params.require_grad = False\n",
        "    params._trainable = False\n",
        "optimizer = torch.optim.AdamW(model.parameters(),lr=2e-5)"
      ],
      "execution_count": 191,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "To-Pgaun-SZd",
        "trusted": true,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tqdm import tqdm\n",
        "epochs = 5"
      ],
      "execution_count": 192,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8iBlS1d4f-Uw",
        "trusted": true,
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "e3f60c97-48b8-4804-9bdb-0e4da3c68cce"
      },
      "source": [
        "\n",
        "for epoch in range(epochs):\n",
        "        \n",
        "        epoch_loss = 0\n",
        "        val_loss = 0\n",
        "        correct = 0\n",
        "        accuracy = 0\n",
        "\n",
        "        for data in train_loader:\n",
        "            ids = data['ids'].cuda()\n",
        "            masks = data['masks'].cuda()\n",
        "            labels = data['labels'].cuda()\n",
        "            labels = labels.unsqueeze(1)\n",
        "            model.train()\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(ids,masks)\n",
        "            loss = criterion(outputs,labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "           \n",
        "            epoch_loss += loss.item()\n",
        "            \n",
        "        print(f'Train Epoch {epoch} : Loss {epoch_loss/len(train_loader)}')\n",
        "        print(\"Train Accuracy : \",binary_acc(outputs,labels))\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        for data in val_loader:\n",
        "            ids = data['ids'].cuda()\n",
        "            masks = data['masks'].cuda()\n",
        "            labels = data['labels'].cuda()\n",
        "            outputs = model(ids,masks)\n",
        "            labels = labels.unsqueeze(1)\n",
        "            loss = criterion(outputs,labels)\n",
        "            val_loss += loss.item()\n",
        "            \n",
        "        print(f'Val Epoch {epoch} : Loss {val_loss/len(val_loader)}')\n",
        "        print(\"Val Accuracy : \",binary_acc(outputs,labels))\n",
        "        if binary_acc(outputs,labels) >90:\n",
        "            break\n"
      ],
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch 0 : Loss 1.6381001019477843\n",
            "Train Accuracy :  38.0\n",
            "Val Epoch 0 : Loss 0.551078716149697\n",
            "Val Accuracy :  69.0\n",
            "Train Epoch 1 : Loss 0.8140286940336228\n",
            "Train Accuracy :  81.0\n",
            "Val Epoch 1 : Loss 0.5062685471314651\n",
            "Val Accuracy :  69.0\n",
            "Train Epoch 2 : Loss 0.5237828180193901\n",
            "Train Accuracy :  75.0\n",
            "Val Epoch 2 : Loss 0.5580048606945918\n",
            "Val Accuracy :  88.0\n",
            "Train Epoch 3 : Loss 0.3948425027728081\n",
            "Train Accuracy :  97.0\n",
            "Val Epoch 3 : Loss 0.5113603518559382\n",
            "Val Accuracy :  88.0\n",
            "Train Epoch 4 : Loss 0.20395209703594447\n",
            "Train Accuracy :  88.0\n",
            "Val Epoch 4 : Loss 0.7078863932536199\n",
            "Val Accuracy :  88.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "6zVo17Q9_Ap2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(sentence):\n",
        "    tokenizer = transformers.DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "    ids = tokenizer.encode(sentence,add_special_tokens=True)\n",
        "    padded = ids + [0]*(80 - len(ids))\n",
        "    padded = torch.tensor(padded,dtype=torch.int64).unsqueeze(0)\n",
        "    masks = torch.where(padded != 0 , torch.tensor(1), torch.tensor(0)).cuda()\n",
        "    padded = padded.cuda()\n",
        "    model.eval()\n",
        "    output = model(padded,masks)\n",
        "    return torch.round(F.sigmoid(output)).item()"
      ],
      "execution_count": 178,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BbyYVYkohEYz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9409c1e1-2ae8-43f0-f201-1ad5cc166c08"
      },
      "source": [
        "test(\"I am feeling warm by this content.\")"
      ],
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 183
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LoVh1SbChHH2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}